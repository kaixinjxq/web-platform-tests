<!DOCTYPE html>
<meta charset="utf-8">
<title>Test MediaStreamTrack interface with Color Stream</title>
<link rel="author" title="Intel" href="http://www.intel.com">
<link rel="help" href="https://w3c.github.io/mediacapture-main">
<script src="../resources/testharness.js"></script>
<script src="../resources/testharnessreport.js"></script>
<meta name="flags" content="interact">

<p class="instructions">Use a test device with color camera(embedded or external).</p>
<p class="instructions">When prompted, accept to share your color stream.</p>

<div id="log"></div>

<video id="vid"></video>
<script>

promise_test(t => {
  let vid = document.getElementById("vid");
  let cv = document.createElement("canvas"); 
  return navigator.mediaDevices.getUserMedia({video: true})
  .then(stream => new Promise(resolve => {
    if (stream.getVideoTracks()[0].enabled) {
      stream.getVideoTracks()[0].enabled = false;
    }

    let testOnceLoadeddata = () => {
      vid.removeEventListener("loadeddata", testOnceLoadeddata, false);
      cv.width = vid.offsetWidth;
      cv.height = vid.offsetHeight;
      let ctx = cv.getContext("2d");
      ctx.drawImage(vid, 0, 0);
      let imageData = ctx.getImageData(0, 0, cv.width, cv.height);
      resolve(imageData);
    }

    vid.srcObject = stream;
    vid.play();
    vid.addEventListener("loadeddata", testOnceLoadeddata, false);
  })).then(imageData => {
      for (let i = 0; i < imageData.data.length; i += 4) {
        assert_equals(imageData.data[i], 0, "No red component in pixel #" + i);
        assert_equals(imageData.data[i + 1], 0, "No green component in pixel #" + i);
        assert_equals(imageData.data[i + 2], 0, "No blue component in pixel #" + i);
        assert_equals(imageData.data[i + 3], 255, "No transparency in pixel #" + i);
      }
  })
}, "Tests that a disabled video track in a MediaStream is rendered as blackness");

promise_test(t => {
  let aud = document.getElementById("aud");
  return navigator.mediaDevices.getUserMedia({audio: true})
  .then(stream => new Promise(resolve => {
    let ctx = new AudioContext();
    let streamSource = ctx.createMediaStreamSource(stream);
    let silenceDetector = ctx.createScriptProcessor(1024);
    let count = 10;
    silenceDetector.onaudioprocess = e => {
      let buffer1 = e.inputBuffer.getChannelData(0);
      let buffer2 = e.inputBuffer.getChannelData(1);
      let out = e.outputBuffer.getChannelData(0);
      out = new Float32Array(buffer1);
      for (let i = 0; i < buffer1.length; i++) {
        assert_equals(buffer1[i], 0, "Audio buffer entry #" + i + " in channel 0 is silent");
      }
      for (let i = 0; i < buffer2.length; i++) {
        assert_equals(buffer2[i], 0, "Audio buffer entry #" + i + " in channel 1 is silent");
      }
      count--;
      if (count === 0) {
        silenceDetector.onaudioprocess = null;
        resolve(count);
      }
    };
    stream.getAudioTracks()[0].enabled = false;

    streamSource.connect(silenceDetector);
    silenceDetector.connect(ctx.destination);
  })).then(count => {
    assert_equals(count, 0);
  })
}, "Tests that a disabled audio track in a MediaStream is rendered as silence", {timeout: 200000});

promise_test(t => {
  return navigator.mediaDevices.getUserMedia({video: true, audio: true})
  .then(stream => {
    assert_not_equals(stream.getVideoTracks()[0].id, stream.getAudioTracks()[0].id, "audio and video tracks have distinct ids");
  })
  .catch(error => {
    assert_unreached("Access to audio and video stream is granted");
  });
}, "Tests that distinct mediastream tracks have distinct ids");

promise_test(t => {
  const constraints = {
    video: true,
    audio: false
  };

  return navigator.mediaDevices.getUserMedia(constraints)
  .then(mediaStream => {
    const settings1 = mediaStream.getVideoTracks()[0].getSettings();
    const videoConstraints = {
      deviceId: settings1.deviceId
    };

    return navigator.mediaDevices.getUserMedia({
      video: videoConstraints,
      audio: false
    }).then(mediaStream => {
      const settings2 = mediaStream.getVideoTracks()[0].getSettings();
      assert_equals(settings1.deviceId, settings2.deviceId);
    });
  });
}, 'A device can be opened twice and have the same device ID');

promise_test(t => {
  const constraints = {
    video: true,
    audio: false
  };

  return navigator.mediaDevices.getUserMedia(constraints)
  .then(mediaStream => {
    const settings1 = mediaStream.getVideoTracks()[0].getSettings();
    const videoConstraints = {
      deviceId: settings1.deviceId,
      width: {
        exact: settings1.width / 2
      }
    };

    return navigator.mediaDevices.getUserMedia({
      video: videoConstraints,
      audio: false
    }).then(mediaStream => {
      const settings2 = mediaStream.getVideoTracks()[0].getSettings();
      assert_equals(settings1.deviceId, settings2.deviceId);
      assert_equals(settings1.width / 2, settings2.width);
    });
  });
}, 'A device can be opened twice with different resolutions');

</script>
